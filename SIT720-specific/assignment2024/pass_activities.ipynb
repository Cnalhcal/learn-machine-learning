{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\" Define a string variable with your name. Print characters of odd and even position of your name.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"Create three variables named 'Student name', 'Course name', and 'EmailAddress'.  \n",
    "    Add 5 random values in these variables,\n",
    "    where added values are not replaceable and print them.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"Create a dictionary variable with three keys, which are named same as the three variables created in the previous problem. \n",
    "    Insert the previously created three variables values in the dictionary variable and print it.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"Define a string variable 'energy' and assign value either 'Fossil' or 'Renewable'. \n",
    "    Print \"Natural gas\" if the value of energy variable is 'Fossil' otherwise print \"solar power\".\n",
    "    What will your program print if energy='Biomass '?\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q5():\n",
    "    \"\"\"Print all prime numbers between 0 and 100 separated by line.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q6():\n",
    "    \"\"\"Is it possible to break a loop before executing for the defined number of iterations? \n",
    "    If yes, provide an example using While loop structure. Otherwise, explain your answer (why and how).\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q7():\n",
    "    \"\"\"Create functions named 'Addition', 'Multiplication', 'Division' and 'Subtraction'. \n",
    "    These functions takes two input parameters say (x, y) and return (x+y),(x*y), (x/y) and (x-y). \n",
    "    Call the function with (4,7) arguments and print the outputs.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q8():\n",
    "    \"\"\"Create and display a 8x8 Identity matrix and multiply it with a 8x4 Random matrix.\n",
    "    Hint: Use np.identity() and np.random.rand()\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q9():\n",
    "    \"\"\"Create a 8x9 matrix, initialise with random values and print it. Now, transpose the matrix and print\n",
    "    it. How the transposed matrix is different from original matrix?\n",
    "    Hint: Use np.random.rand() and np.transpose()\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q10():\n",
    "    \"\"\"Expport the \"PedestrianCounting.csv\" file as a matrix. \n",
    "    The row of the matrix represents data point or instance and the column represents the variable or feature. \n",
    "    Print the number of data instances and variables present in this dataset. Calculate mean of the third variable \n",
    "    and deduct this mean from original values of the variable. Print both original and modified values of the variable. \n",
    "    Hint:  Use pd.read_csv(); np.mean(\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"Read \"sensor-readings-with-temperature-light-humidity-every-5-minutes-at-8-locations-t.csv\" and print the feature name with numbers of missing entries.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"Fill in the missing entries. For filling any feature, you can use either the mean or median value of the feature values from observed entries. \n",
    "    Explain the reason behind your choice and print replacement value of each feature.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"Encode the categorical variable  location\" using an appropriate encoding approach and display the encoded values. \n",
    "    Justify your selection of encoding approach.  Save the modified data into a csv file and upload it to Ontrack.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"Apply the min-max scaling on features \"[boardtype, boardid ,temp_max, temp_min, temp_avg,light_max, light_min,light_avg, humidity_min, humidity_max, humidity_avg]\" . \n",
    "    Plot distribution of first six features before and after scaling. Is there any difference? Please explain.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"Load data from \"Live_20210128.csv\" file. Remove unwanted features if required.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"Select the optimum k value for clustering using Silhouette Coefficient and plot the optimum k values.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    Create clusters using Kmeans and Kmeans++ algorithms with the optimal k value found in the previous problem.\n",
    "    Report performances using appropriate evaluation metrics. Compare the results.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"\n",
    "    Repeat clustering using Kmeans for 50 times and report the average performance.\n",
    "    Compare the results obtained in Q3 using Kmeans++ and explain the difference (if any).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# 720\n",
    "def Q5():\n",
    "    \"\"\"\n",
    "    Apply DBSCAN on the dataset \"Live_20210128.csv\" and find the optimum \"eps\" and \"min_samples\" value.\n",
    "    Check if the number of clusters is the same as the cluster found in Q2. Explain the similarities or differences\n",
    "    that you have found between the two solutions.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"\n",
    "    1. Load the \"diabetes\" dataset from SKlearn and apply PCA to generate 3 principal components.\n",
    "    2. Plot the first three components of the PCA.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    Compute the variance (%) covered by the first 3 components of the PCA applied on the \"diabetes\" dataset.\n",
    "    Explain how this percentage of variance is computed.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    Analyze if there is any correlation between the first three components generated by PCA on the \"diabetes\" dataset.\n",
    "    Discuss your findings.\n",
    "    \"\"\"\n",
    "    pass\n",
    " \n",
    "\n",
    "# 720\n",
    "def Q4():\n",
    "    \"\"\"\n",
    "    Apply t-SNE with method 'exact' on the \"diabetes\" dataset to generate a representation with the same number of components used in PCA.\n",
    "    Plot the first three components obtained from t-SNE.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q5():\n",
    "    \"\"\"\n",
    "    Report a comparison between the k-means clustering results obtained using t-SNE and PCA.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"\n",
    "    Load the dataset from \"data.csv\". Create training and test datasets using random splitting (80-20)%.\n",
    "    Print the number of samples in train and test data groupby \"roof_type\".\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    Create training and test dataset using leave 5 \"property_id\" out for testing and the rest of them for training.\n",
    "    Print the train and test dataset for the first iteration only. Compare with Q1 in terms of the number of training\n",
    "    and testing samples using a bar graph.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"\n",
    "    1. Download and read the \"Real estate valuation data set.xIsx\" dataset from the UCI repository.\n",
    "    Find the description of the features and targets on the UCI repository website. Split the dataset\n",
    "    into train and test set (use your choice of splitting). Train a linear regression model and report\n",
    "    the performance using at least four performance metrics.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    2. Apply PCA on the \"Real estate valuation data set\" and select the first three principal components.\n",
    "    Split the dataset into train and test using the same method used in Q1. Compare the performance of\n",
    "    this model with the performance obtained in Q1. Explain the outcome.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    3. Load the \"IRIS\" dataset from SKlearn and follow the provided link for the data description\n",
    "    (features and target variable). \n",
    "    Apply PCA on the dataset and select the first three principal components.\n",
    "    Split the dataset into train and test set (use your choice of splitting). \n",
    "    Train a logistic regression\n",
    "    model and report the performance using at least four performance metrics.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"\n",
    "    4. Apply L1 or L2 regularizer on the logistic regression model developed using the same train and test\n",
    "    data used in Q3 and calculate the performance of the new model. \n",
    "    Compare performance of this model with the performance reported in Q3. Explain the outcome.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Q1():\n",
    "    \"\"\"\n",
    "    1. Download and read the \"Real estate valuation data set.xIsx\" dataset from the UCI repository.\n",
    "    Find the description of the features and targets on the UCI repository website. Split the dataset\n",
    "    into train and test set (use your choice of splitting). Train a linear regression model and report\n",
    "    the performance using at least four performance metrics.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    2. Apply PCA on the \"Real estate valuation data set\" and select the first three principal components.\n",
    "    Split the dataset into train and test using the same method used in Q1. Compare the performance of\n",
    "    this model with the performance obtained in Q1. Explain the outcome.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# 720\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    3. Load the \"IRIS\" dataset from SKlearn and follow the provided link for the data description\n",
    "    (features and target variable). Apply PCA on the dataset and select the first three principal components.\n",
    "    Split the dataset into train and test set (use your choice of splitting). Train a logistic regression\n",
    "    model and report the performance using at least four performance metrics.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"\n",
    "    4. Apply L1 or L2 regularizer on the logistic regression model developed using the same train and test\n",
    "    data used in Q3 and calculate the performance of the new model. Compare performance of this model with\n",
    "    the performance reported in Q3. Explain the outcome.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"\n",
    "    Download Electrical Grid Stability Simulated Data and classify \"Electrical Grid Stability Simulated Data\" classes using KNN.\n",
    "    Use the same data splitting and performance metrics that have been used in week 7, Q-2.\n",
    "    Report your findings including a comparison of results with week 7.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    Load Electrical Grid Stability Simulated Data and create a classification model using the DT algorithm with 50-50% and 80-20% data splitting methods.\n",
    "    Compare the performances of these two models and explain the impact of the difference in data splitting on the performances of the model.\n",
    "    \"\"\"\n",
    "    pass\n",
    "# 720\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    Create two more KNN-based classification models using the dataset from Q1 by varying distance metrics, such as using cityblock and manhattan.\n",
    "    Report the performances of the developed models including the model from Q1 and explain the similarities or differences, if any.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"Load \"data.csv\" dataset and create an ensemble ML model for predicting the target variable (Result). Report the performance of the model using appropriate metrics.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"If hyperparameter tuning was used in Q1, plot the performances that were obtained at different steps of optimization. Otherwise, create an optimized model and compare performance with Q1.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"Reflect on the importance of hyperparameter tuning of ML models based on your ML model development exercise.\"\"\"\n",
    "    pass\n",
    "\n",
    "# 720\n",
    "\n",
    "def Q4():\n",
    "    \"\"\"Create a GradientBoost model for predicting the Result using the same dataset that was used in Q1 and report the performance.\"\"\"\n",
    "    pass\n",
    "\n",
    "def Q5():\n",
    "    \"\"\"Compare the performance of two models (Q1 and Q4). Explain which model is good and why.\"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1():\n",
    "    \"\"\"\n",
    "    Create a MLP (Multi-Layer Perceptron) model with 10 hidden layers using the \"data.csv\" dataset. \n",
    "    Evaluate and report the model's performance using appropriate metrics.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q2():\n",
    "    \"\"\"\n",
    "    Analyse the impact of different activation functions with the Adam solver on the MLP model's performance.\n",
    "    Experiment with at least three different activation functions and compare their effects on the model.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def Q3():\n",
    "    \"\"\"\n",
    "    Explain your findings from the experiments with different activation functions and the Adam solver.\n",
    "    Report the best performing activation function based on the evaluation metrics used in Q1.\n",
    "    Discuss why this activation function performed the best in your model configuration.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
