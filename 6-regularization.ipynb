{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "* The second term : maximize Pr(parameters|data) $\\propto$ Pr(data|parameters) * Pr(parameters)\n",
    "    * Bias (fit the training data) and Variance (generalize to predict unseen data points)\n",
    "    * Reducing Model Complexity\n",
    "\n",
    "* L1, L2 Regularization \n",
    "    * Lasso (L1) and Ridge (L2) for linear regression\n",
    "    * Regularization for logistic regression\n",
    "    <center><img src=\"pics/l1_l2_on_logistic_regression.png\" width=\"500\"></center>\n",
    "\n",
    "    * L1 tends to perform better when only a small number of predictor variables are significant, as it can remove insignificant variables completely from the model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
