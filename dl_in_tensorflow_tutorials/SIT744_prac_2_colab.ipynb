{"cells":[{"cell_type":"markdown","metadata":{"id":"ZeHe2I9Ix2iM"},"source":["# SIT744 Practical 2: Introduction to TensorFlow\n","\n","\n","*Prof. Antonio Robles-Kelly*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wSJnyS9Fy51S"},"source":["<div class=\"alert alert-info\">\n","We suggest that you run this notebook using Google Colab.\n","</div>\n","\n","- Go through [this tutorial](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb) of TensorFlow using Keras in Google Colab. *You do not need to understand anything at this stage; Just get an idea of how Keras works.*\n","- Read through [this blog](https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html) to understand how Keras and TensorBoard fit in the TensorFlow 2.0 eco-system. *Again, don't worry if you don't understand everything mentioned there.*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vFIXRAjmedgo"},"source":["## Task 1. TensorFlow\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E9uo0W4pzi66"},"source":["TensorFlow contains the following key components:\n","\n","- A NumPy-like data model with GPU support.\n","- A computation model based on the computation graph.\n","- A library to compute gradients and perform gradient descent."]},{"cell_type":"markdown","metadata":{"id":"tJeteTjZ-X0X"},"source":["### Loading TensorFlow 2.0 in Colab\n","We use TensorFlow 2.0 in this unit. It is much more user-friendly compared with the previous version.\n","\n","In Google Colab, you can specify TensorFlow 2.0 to be used as below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQnvPHesHx2l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"-R2qv1A0-e03"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.16.2\n"]}],"source":["#%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"D8FkvOWRn_zj"},"source":["### Create Tensors from NumPy"]},{"cell_type":"markdown","metadata":{"id":"DIkXr2Bxpqi8"},"source":["Tensors can be created from NumPy arrays and vice versa.\n","\n","Which of the variables below contain tensors?\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"2Z4GZj4LpStS"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n","<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n"]}],"source":["import numpy as np\n","\n","a = np.ones(5)\n","print(type(tf.constant(a)))\n","print(type(tf.Variable(a)))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TSyj9VgWqRne"},"source":["Many operations for ndarrays have counterparts for tensors."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"b89BD4Meqdy0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[4. 4. 4. 4. 4.]\n","tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float64)\n"]}],"source":["print(a + 3)  # NumPy\n","print(b + 3)  # TensorFlow"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R5RWN_FoqjmD"},"outputs":[{"name":"stdout","output_type":"stream","text":["[4. 4. 4. 4. 4.]\n","tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float64)\n"]}],"source":["print(np.square(a + 1)) # NumPy\n","print(tf.square(b + 1)) # TensorFlow"]},{"cell_type":"markdown","metadata":{"id":"7HiIB5t7q07C"},"source":["However, for computational efficiency, TensorFlow avoids automatic type conversions. Integers are often not very useful in TensorFlow."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"8HhSvSo1rDnv"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([4, 5, 6], dtype=int32)>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["d = tf.constant(3)\n","b = tf.constant([1, 2, 3])\n","d+b\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"YGAKrdMkrgit"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=int32, numpy=3>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["d"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"mGXr0_TqrmxT"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5,), dtype=float64, numpy=array([4., 4., 4., 4., 4.])>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["## This works\n","b + tf.cast(d, tf.float64)"]},{"cell_type":"markdown","metadata":{"id":"4p5idadWmq5Q"},"source":["### Why Tensor? Why GPU?\n","\n","A tensor is similar to a NumPy ndarray, but with GPU support. Let's first make sure that a GPU is enabled."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TTjPM9d6kNph"},"outputs":[{"name":"stdout","output_type":"stream","text":["/device:GPU:0\n","Num GPUs Available:  1\n","These are: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]},{"name":"stderr","output_type":"stream","text":["2024-07-14 16:15:38.428213: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2024-07-14 16:15:38.428248: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["print(tf.test.gpu_device_name())\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","print(\"These are:\",tf.config.experimental.list_physical_devices('GPU'))"]},{"cell_type":"markdown","metadata":{"id":"DsMl6AbgnvIi"},"source":["Now compare the running time with GPU and without GPU."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"gLykm481nhPS"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(-13995.58, shape=(), dtype=float32)\n","CPU times: user 5.81 s, sys: 3.09 s, total: 8.9 s\n","Wall time: 2.33 s\n"]}],"source":[" %%time\n"," with tf.device('/cpu:0'):\n","    random_image = tf.random.normal((10000, 10000, 3))\n","    tf.math.reduce_sum(random_image)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"I_8JxouznB8Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 48.1 ms, sys: 56.4 ms, total: 104 ms\n","Wall time: 114 ms\n"]}],"source":[" %%time\n"," with tf.device('/device:GPU:0'):\n","    random_image = tf.random.normal((10000, 10000, 3))\n","    tf.math.reduce_sum(random_image)"]},{"cell_type":"markdown","metadata":{"id":"v1XQAobcnsUU"},"source":["## Task 2 TensorBoard\n","\n","Tensorboard is a convenient visualisation tool that comes with TensorFlow. You have read in [this blog post](https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html) that TensorBoard is the default analysis tool in TensorFlow 2.x. You can use it to visualise computation graphs and training metrics and much more.\n","\n","Run through [this tutorial](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/get_started.ipynb) in Google Colab. If you don't understand everything, it is fine, as we will revisit TensorBoard with Keras later on.\n"]},{"cell_type":"markdown","metadata":{"id":"hjH28jbA3Iw1"},"source":["\n","### Input for TensorBoard\n","\n","Here is how TensorBoard expect the input data to be organised.\n","\n","#### logdir\n","TensorBoard looks into a log folder *logdir*, which contains **summary data** to visualise.\n","\n","#### runs\n","\n","You may organise the summary data from difference executions of your model into subfolders under *logdir*. These subfolders will become different **runs** in the TensorBoard.\n","\n","\n","#### event files\n","\n","You use TensorFlow's `tf.summary` API (or indirectly via Keras callbacks) to generate log files, which are call **event files** in *logdir*. These files will automatically have \"tfevents\" in their file names. Each file contains records called *summaries*.\n","\n","#### tags\n","\n","You add tags to a summary by passing a `name` argument in `tf.summary` calls (See examples below). In TensorBoard, these tags allow you to filter data to be visualised.\n","\n","\n","#### Two ways to generate TensorBoard logs\n","\n","As suggested before, there are two ways to generate TensorBoard logs: through the high-level Keras callbacks or directly use the *tf.summary* API. We will introduce Keras later in this unit. For now, let's focus on *tf.summary*.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"bG-dALETFCWL"},"source":["### Task 2.1 Creat logdir\n","\n","As mentioned above, it is a common practice to keep logs from different training runs in separate folders so that we can compare the learning curves across multiple runs. Below shows a common trick to use datetime to generate a unique folder for the current training run."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"ui262WwcrMBd"},"outputs":[],"source":["from datetime import datetime\n","import os\n","root_logdir = \"logs\"\n","run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","logdir = os.path.join(root_logdir, run_id)\n"]},{"cell_type":"markdown","metadata":{"id":"PZZKRlUlt8nr"},"source":["Then we use that folder for logging."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"F57frfBRs6cV"},"outputs":[],"source":["# Clear any logs from previous runs\n","import shutil\n","\n","#!rm -rf ./logs/\n","\n","logs_dir_path = './logs/'\n","if os.path.isdir(logs_dir_path):\n","  shutil.rmtree(logs_dir_path)\n","\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["file_writer = tf.summary.create_file_writer(logdir)"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"5C6hD95fpILb"},"outputs":[],"source":["\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"kMNglTF02_73"},"source":["### Visualise computation graph\n","\n","To visualise TensorFlow computation graphs in TensorBoard, you need two functions `tf.summary.trace_on()` and `tf.summary.trace_export()`."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"8cfIdTAE4FaJ"},"outputs":[],"source":["# The function to be traced.\n","@tf.function\n","def my_prod(x, y):\n","    return tf.matmul(x, y)\n","\n","def my_min(B):\n","    return tf.reduce_min(B)\n","\n","def my_max(B):\n","    return tf.reduce_max(B)\n","\n","# Sample data for your function.\n","x = tf.random.uniform((3, 3))\n","y = tf.random.uniform((3, 3))\n","\n","# Bracket the function call with\n","# tf.summary.trace_on() and tf.summary.trace_export().\n","tf.summary.trace_on(graph=True)\n","\n","# Call only one tf.function when tracing.\n","z = my_prod(x, y)\n","with file_writer.as_default():\n","  tf.summary.trace_export(\n","      name=\"my_func_trace\",\n","      step=0,\n","      profiler_outdir=logdir)\n","tf.summary.trace_off()\n","\n","A = my_prod(x, y)\n","A = (A-my_min(A))/(my_max(A)-my_min(A))\n","A = tf.expand_dims(A, 2)\n","A = tf.expand_dims(A, 0)\n","# Using the file writer, log the reshaped image.\n","with file_writer.as_default():\n","  tf.summary.image(\"my_matrix_multiplication\", A, step=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnTt_wBpyEWK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"c5Ssuq37vAhp"},"source":["#### Show log in TensorBoard\n","\n","To load TensorBoard in Jupyter, follow the example below.\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"Q8BI6GeaoGEQ"},"outputs":[{"data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 73651), started 1 day, 21:36:42 ago. (Use '!kill 73651' to kill it.)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-e09ce08a5a56630a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-e09ce08a5a56630a\");\n","          const url = new URL(\"http://localhost\");\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# %reload_ext tensorboard\n","%tensorboard --logdir logs\n","\n","@tf.function\n","def my_prod(x, y):\n","    a = tf.matmul(x, y)"]},{"cell_type":"markdown","metadata":{"id":"mjXl4-wW45uI"},"source":["You should be able to see a **GRAPHS** tab and there you can find the computation graph."]},{"cell_type":"markdown","metadata":{"id":"DbSV8UhjKjhR"},"source":["**Exercise**: Follow the example above to display the computation graph of the function $z = 3 x^2 + 2xy$. (*Hint: You may need a different tag.*)"]},{"cell_type":"markdown","metadata":{"id":"9IV4CliHv0Cz"},"source":["### Log (training) metrics\n","\n","Besides visualising the computation graph, TensorBoard can also be used to log training metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFYnjK2ar9_p"},"outputs":[],"source":["with file_writer.as_default():\n","  for step in range(200):\n","    tf.summary.scalar(name=\"my_metric\", data=0.5, step=step)\n","    file_writer.flush()"]},{"cell_type":"markdown","metadata":{"id":"mnR_hXdfJbJl"},"source":["**Exercise**:\n","1. Follow the example above to log the value of the sine function from 0 to 100; Display the values in TensorBoard. (*Hint: use a different tag.*)\n","2. Create another run. And plot the cosine function instead. (*Hint: use a different summary writer.*)"]},{"cell_type":"markdown","metadata":{"id":"P82VgscODrJO"},"source":["## Task 3. AutoDiff\n","\n","Computing gradient is a core requirement for training deep learning models. In TensorFlow, this is done automatically by the software. If you use Keras, in most cases, you specify an optimiser in the `fit` function and don't need to access the gradients directly. However, to access the computed gradients, you can follow the example below."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"FljRqmmM4Syj"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(16.0, shape=(), dtype=float32)\n"]}],"source":["x = tf.Variable(4.0)\n","\n","def func(x):\n","  return x**2\n","\n","with tf.GradientTape() as t:\n","  y = func(x)\n","  loss = 2*y\n","\n","dy_dx = t.gradient(loss, x)\n","print(dy_dx)\n"]},{"cell_type":"markdown","metadata":{"id":"4dLgkI7BA0-4"},"source":["**Exercise**: Follow the example above to compute the gradient of function $z(x,y) = 3 x^2 + 2xy$."]},{"cell_type":"markdown","metadata":{"id":"cbd7zbd1NW42"},"source":["## Additional resources\n","\n","- TensorFlow guide on [Examining the TensorFlow Graph](https://www.tensorflow.org/tensorboard/graphs)\n","- TensorFlow tutorial on [Automatic differentiation and gradient tape](https://www.tensorflow.org/tutorials/customization/autodiff)\n","- [Calculus on Computational Graphs: Backpropagation](https://colah.github.io/posts/2015-08-Backprop/)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
