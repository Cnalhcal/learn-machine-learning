{"cells":[{"cell_type":"markdown","metadata":{"id":"ZeHe2I9Ix2iM"},"source":["# SIT744 Practical 4: Second look at TensorFlow and Keras\n","\n","\n","*Prof. Antonio Robles-Kelly*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"l--dd-g0DOiD"},"source":["<div class=\"alert alert-info\">\n","We suggest that you run this notebook using Google Colab.\n","</div>\n","\n","## Pre-practical readings\n","\n","- [TensorFlow tensors](https://www.tensorflow.org/guide/tensor)\n","- [TensorFlow Variables](https://www.tensorflow.org/guide/variable)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6qqyuRZ3GmPj"},"source":["## Task 1. Low-level tensor manipulation in TensorFlow\n","\n","TensorFlow APIs cover three deep-learning components:\n","\n","- Tensors, including variables for keeping layer weights\n","- Tensor operations, including tensor multiplication,  addition, and the activation functions\n","- Backpropagation, implemented through the GradientTape object\n","\n","In this task, we will learn how to use these TensorFlow components. "]},{"cell_type":"markdown","metadata":{"id":"TJVIrhwYGwCg"},"source":["### Task 1.1 Tensors and tensor operations"]},{"cell_type":"markdown","metadata":{"id":"Za_ox3Xeit20"},"source":["\n","\n","#### tf.Tensor vs tensors\n","\n","We mentioned that tensors (with lower-case t) are like NumPy arrays. However, [`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) (with upper-case T) is different. A tf.Tensor defines a function (or computation) that, when called, produces a tensor. Such a function is called an **Operator** in the TensorFlow nomenclature.\n","\n","Therefore, a TensorFlow program forms a computation graph that chains a collection of tf.Tensor's together. You can think that the program  itself contains no data. When we invoke the program, data (tensors) are generated or passed in and flow through operators in the program. But how can we store the model parameters and train the model parameters?"]},{"cell_type":"markdown","metadata":{"id":"3x8D8V-2ixES"},"source":["\n","\n","#### Constant tensors and Variables\n","\n","Assuming that we separate data from computation. Then `tf.constant` and `tf.Variable` are the two main `tf.Tensor` that directly deal with data. Data in `tf.constant` is immutable and data in `tf.Variable` can be changed.\n","\n","Constant tensors return the same data at every invocation of the computation graph.\n"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8003,"status":"ok","timestamp":1626925440070,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"tq3b2gtaRFxe","outputId":"10cf52b1-76bb-46b8-8da4-e28c641d92a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n"]}],"source":["\n","import tensorflow as tf\n","\n","a = tf.constant([[1, 2],\n","                 [3, 4]])\n","print(type(a))\n"]},{"cell_type":"markdown","metadata":{"id":"1sUVaVzpWy94"},"source":["As you can see that `tf.constant` returns a tensor. There are some other functions that return constant tensors."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1626925440071,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"jkhiymqTWbAl","outputId":"0e791f78-6ec8-4cfd-ad7d-ad4f3bed3018"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[1. 1.]\n"," [1. 1.]], shape=(2, 2), dtype=float32)\n","tf.Tensor(\n","[[0. 0.]\n"," [0. 0.]], shape=(2, 2), dtype=float32)\n"]}],"source":["x = tf.ones(shape=(2, 2))\n","print(x)\n","x = tf.zeros(shape=(2, 2))\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"PqERjp2DYL1z"},"source":["A particularly important class of functions are those used for generating random initial weights in a network. They produced constant tensors as the initial values for variables.  "]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1626925440072,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"Q-MAXnakY_-5","outputId":"f6614ebe-ca52-41b1-e6bd-d6f85c8ac426"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n","tf.Tensor(\n","[[ 9.93228  10.035228 10.001833]\n"," [10.043459 10.021921  9.97328 ]], shape=(2, 3), dtype=float32)\n"]}],"source":["## Normal initialiser\n","w_init = tf.random_normal_initializer(\n","    mean=10.0, stddev=0.05, seed=None\n",")\n","\n","initial_value=w_init(shape=(2, 3),\n","                     dtype='float32')\n","print(type(initial_value))\n","print(initial_value)\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[ 0.04221221,  0.01397283],\n","       [ 0.02129208, -0.02218554]], dtype=float32)>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["initial_value"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[-0.0188207   0.03263413]\n"," [ 0.01849456 -0.04932909]], shape=(2, 2), dtype=float32)\n"]}],"source":["## Uniform initialiser\n","w_init = tf.random_uniform_initializer(\n","    minval = -0.05, maxval = 0.05, seed=None\n",")\n","\n","initial_value=w_init(shape=(2, 2),\n","                     dtype='float32')\n","\n","print(initial_value)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AyEx_1Lyf09n"},"source":["**exercise** Try to assign a new value to a constant tensor. Can you do that?"]},{"cell_type":"markdown","metadata":{"id":"4daBVDTUgES4"},"source":["In comparison to constants, variables can be assigned a different value. They are required to represent trainable network/layer weights"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626925440072,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"oO5-Vy5Cgk98","outputId":"006fda9e-e948-49f4-d034-f5a3ec7cdcaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[-0.0188207 ,  0.03263413],\n","       [ 0.01849456, -0.04932909]], dtype=float32)>\n"]}],"source":["w = tf.Variable(initial_value=initial_value,\n","                         trainable=False)\n","print(w)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["# w = w.assign_sub(tf.constant(0.1, shape=(2, 2)))"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[None]\n"]}],"source":["with tf.GradientTape() as paper:\n","   z = tf.sqrt(w)\n","\n","dz_dx = paper.gradient(z, [w])\n","print(dz_dx)"]},{"cell_type":"markdown","metadata":{"id":"HnsodVqShn0H"},"source":["You can use the `assign` function to change the value in a variable."]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1626925440073,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"gILckVTthCgY","outputId":"b9a155cd-1401-4f81-bb3b-7433a11158ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(-0.018820703, shape=(), dtype=float32)\n"]},{"ename":"InvalidArgumentError","evalue":"Cannot assign a device for operation ResourceStridedSliceAssign: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nResourceStridedSliceAssign: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  ref (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  ResourceStridedSliceAssign (ResourceStridedSliceAssign) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: ResourceStridedSliceAssign\nNode attrs: Index=DT_INT32, shrink_axis_mask=3, new_axis_mask=0, begin_mask=0, ellipsis_mask=0, end_mask=0, T=DT_FLOAT\nRegistered kernels:\n  device='XLA_CPU_JIT'; Index in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN, DT_INT4, DT_UINT4]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_QINT8]\n  device='CPU'; T in [DT_QUINT8]\n  device='CPU'; T in [DT_QINT32]\n  device='CPU'; T in [DT_FLOAT8_E5M2]\n  device='CPU'; T in [DT_FLOAT8_E4M3FN]\n\n\t [[{{node ResourceStridedSliceAssign}}]] [Op:ResourceStridedSliceAssign] name: strided_slice/_assign","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(w[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(w[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1117\u001b[0m, in \u001b[0;36mstrided_slice.<locals>.assign\u001b[0;34m(val, name)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m   name \u001b[38;5;241m=\u001b[39m parent_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_assign\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strided_slice_assign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1543\u001b[0m, in \u001b[0;36mBaseResourceVariable._strided_slice_assign\u001b[0;34m(self, begin, end, strides, value, name, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strided_slice_assign\u001b[39m(\u001b[38;5;28mself\u001b[39m, begin, end, strides, value, name, begin_mask,\n\u001b[1;32m   1539\u001b[0m                           end_mask, ellipsis_mask, new_axis_mask,\n\u001b[1;32m   1540\u001b[0m                           shrink_axis_mask):\n\u001b[1;32m   1541\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _handle_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dependencies():\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(\n\u001b[0;32m-> 1543\u001b[0m         \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_strided_slice_assign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m            \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:8827\u001b[0m, in \u001b[0;36mresource_strided_slice_assign\u001b[0;34m(ref, begin, end, strides, value, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8825\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   8826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 8827\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8828\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   8829\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation ResourceStridedSliceAssign: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nResourceStridedSliceAssign: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  ref (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  ResourceStridedSliceAssign (ResourceStridedSliceAssign) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: ResourceStridedSliceAssign\nNode attrs: Index=DT_INT32, shrink_axis_mask=3, new_axis_mask=0, begin_mask=0, ellipsis_mask=0, end_mask=0, T=DT_FLOAT\nRegistered kernels:\n  device='XLA_CPU_JIT'; Index in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN, DT_INT4, DT_UINT4]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_QINT8]\n  device='CPU'; T in [DT_QUINT8]\n  device='CPU'; T in [DT_QINT32]\n  device='CPU'; T in [DT_FLOAT8_E5M2]\n  device='CPU'; T in [DT_FLOAT8_E4M3FN]\n\n\t [[{{node ResourceStridedSliceAssign}}]] [Op:ResourceStridedSliceAssign] name: strided_slice/_assign"]}],"source":["print(w[0,0])\n","\n","\n","w[0,0].assign(0)\n","print(w[0,0])"]},{"cell_type":"markdown","metadata":{"id":"IOXmlZ0ai_uo"},"source":["### Task 1.2 Math operations in TensorFlow\n","\n","The transformation of tensors are achieved by matrix multiplications, additions, reshaping, and activation functions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2692,"status":"ok","timestamp":1626925442759,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"w2st7tlXj3_K","outputId":"632aaba4-e2b7-4ba1-e5ad-6d64eeaf1f27"},"outputs":[{"name":"stdout","output_type":"stream","text":["a: [[1. 1.]\n"," [1. 1.]]\n","b: [[1. 1.]\n"," [1. 1.]]\n","c: [[1. 1.]\n"," [1. 1.]]\n","d = b + c: [[2. 2.]\n"," [2. 2.]]\n","e = tf.matmul(a, b): [[2. 2.]\n"," [2. 2.]]\n","e *= d: [[4. 4.]\n"," [4. 4.]]\n"]}],"source":["a = tf.ones((2, 2))\n","print(f'a: {a}')\n","b = tf.square(a)\n","print(f'b: {b}')\n","c = tf.sqrt(a)\n","print(f'c: {c}')\n","d = b + c\n","print(f'd = b + c: {d}')\n","e = tf.matmul(a, b)\n","print(f'e = tf.matmul(a, b): {e}')\n","e *= d\n","print(f'e *= d: {e}')"]},{"cell_type":"markdown","metadata":{"id":"EtjaWP2KlwIG"},"source":["### Task 1.3 Performing differentiation with tensor operations\n","\n","Tensor operations come with the ability to perform automatic differentiation."]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1626925442760,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"JztuHNjymED5","outputId":"619a0932-6cdc-485f-a5c4-7e87f6737f73"},"outputs":[{"name":"stdout","output_type":"stream","text":["x:\n"," <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[1., 1.],\n","       [1., 1.]], dtype=float32)>\n","y:\n"," tf.Tensor(\n","[[1. 1.]\n"," [1. 1.]], shape=(2, 2), dtype=float32)\n","dy_dx:\n"," tf.Tensor(\n","[[2. 2.]\n"," [2. 2.]], shape=(2, 2), dtype=float32)\n"]}],"source":["x = tf.Variable(initial_value= tf.ones((2,2)))\n","\n","print('x:\\n', x)\n","with tf.GradientTape() as tape:\n","   y = tf.square(x)\n","print('y:\\n', y)\n","dy_dx = tape.gradient(y, x)\n","print('dy_dx:\\n', dy_dx)\n","\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:1005\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient using operations recorded in context of this tape.\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03mNote: Unless you set `persistent=True` a GradientTape can only be used to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;124;03m   called with an unknown value.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA non-persistent GradientTape can only be used to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute one set of gradients (or jacobians)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recording:\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n","\u001b[0;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"]}],"source":["tape.gradient(y, x)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.5, 0.5],\n","       [0.5, 0.5]], dtype=float32)>]\n"]}],"source":["with tf.GradientTape() as paper:\n","   z = tf.sqrt(x)\n","\n","dz_dx = paper.gradient(z, [x])\n","\n","\n","print(dz_dx)"]},{"cell_type":"markdown","metadata":{"id":"l1vdti4sm_ET"},"source":["**exercise** Modify the code above to compute the gradient of the exponential function $y=e^{x}$.\n","\n","**question** Can you call `tape.gradient` twice?\n"]},{"cell_type":"markdown","metadata":{"id":"NVBPzC3pCFeH"},"source":["## Task 2  Reimplementing a Keras model in TensorFlow\n","\n","Last week, we used a Keras model to run through the MNIST example. In this practical, we learn how to reimplement the model without using Keras. This will deepen your understanding of some key concepts.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VFn0BndZDORM"},"source":["### Task 2.1 A simple Dense class\n","\n","We know that a dense layer is essentially performing an affine transformation followed by an activation function.\n","\n","> output = activation(dot(W, input) + b)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZgkoyWBOY3Y5"},"source":["We can define a class for network layers.\n"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"_OiUXe6qDtpA"},"outputs":[],"source":["class NaiveDense:\n","\n","    def __init__(self, units, input_dim, activation):\n","        self.activation = activation\n","\n","        W_init = tf.random_normal_initializer()\n","        self.W = tf.Variable(initial_value=W_init(shape=(input_dim, units),\n","                                              dtype='float32'),\n","                         trainable=True)\n","\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(initial_value=b_init(shape=(units,),\n","                                              dtype='float32'),\n","                         trainable=True)\n","        \n","    def __call__(self, inputs):\n","        return self.activation(tf.matmul(inputs, self.W) + self.b)\n","\n","    @property\n","    def weights(self):\n","        return [self.W, self.b]"]},{"cell_type":"markdown","metadata":{"id":"CwVnV45HZNGA"},"source":["Let's try to pass a tensor through the layer."]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1626925442761,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"EcZK6Ik91hYM","outputId":"8584ea8f-76fc-4938-b2ec-4b1dfd6b2ab6"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[0.00330251 0.0982748  0.         0.         0.0186949  0.\n","  0.04624053 0.11196592 0.         0.        ]\n"," [0.00330251 0.0982748  0.         0.         0.0186949  0.\n","  0.04624053 0.11196592 0.         0.        ]], shape=(2, 10), dtype=float32)\n"]}],"source":["relu_layer = NaiveDense(units=10, input_dim=2, activation = tf.nn.relu)\n","\n","x = tf.ones((2, 2))\n","y = relu_layer(x)\n","print(y)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mUc4le2VRI_r"},"source":["You can compare this with the original implementation from Keras. The difference in values is due to random initialisation."]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1626925442761,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"y-P3mu82Q-Fu","outputId":"172a3a29-c4cc-41fa-e8f7-434bf1ad5d70"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[0.         0.         0.32536697 0.         0.         0.\n","  0.         0.01500052 0.         0.        ]\n"," [0.         0.         0.32536697 0.         0.         0.\n","  0.         0.01500052 0.         0.        ]], shape=(2, 10), dtype=float32)\n"]}],"source":["keras_layer = tf.keras.layers.Dense(units=10, activation = tf.nn.relu)\n","y = keras_layer(x)\n","print(y)"]},{"cell_type":"markdown","metadata":{"id":"UmTP7AnDMTx3"},"source":["**question** Do you see negative values in the output? Why? Are we using the 10 output units effectively?"]},{"cell_type":"markdown","metadata":{"id":"vFIXRAjmedgo"},"source":["### Task 2.2 A simple Sequential class\n","\n","Once we have defined some layers, we can chain them together. Let's define a class similar to the Sequential Model in Keras.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"pA_l3xFOZ2Ra"},"outputs":[],"source":["class NaiveSequential:\n","\n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, inputs):\n","        x = inputs\n","        for layer in self.layers:\n","           x = layer(x)\n","        return x\n","\n","    @property\n","    def weights(self):\n","       weights = []\n","       for layer in self.layers:\n","           weights += layer.weights\n","       return weights"]},{"cell_type":"markdown","metadata":{"id":"WJBlvhAAZ3KY"},"source":["It takes a list of layers and returns a model."]},{"cell_type":"code","execution_count":83,"metadata":{"id":"qJfzpqFSYEAa"},"outputs":[],"source":["model = NaiveSequential([\n","    NaiveDense(units=512, input_dim=28 * 28, activation=tf.nn.relu),\n","    NaiveDense(units=10, input_dim=512,  activation=tf.nn.softmax)\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"gtYRMuhUazKf"},"source":["Let's try to feed the model two identical \"images\".\n"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1626925443724,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"oVcWreS4aPTu","outputId":"ab148f39-87ae-48e2-b446-8548e3861d6b"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n","array([[0.03235335, 0.19014378, 0.07470462, 0.14178684, 0.03212496,\n","        0.05677064, 0.2146402 , 0.16345944, 0.03473785, 0.05927834],\n","       [0.03235335, 0.19014378, 0.07470462, 0.14178684, 0.03212496,\n","        0.05677064, 0.2146402 , 0.16345944, 0.03473785, 0.05927834]],\n","      dtype=float32)>"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["model(tf.ones((2, 28 * 28)))"]},{"cell_type":"markdown","metadata":{"id":"La67OKRHGtH0"},"source":["### Task 2.3 A batch generator\n","\n","To run stochastic gradient-descent, we need to feed the model with mini-batches of the input data. Later on, we will learn how to build TensorFlow input pipelines with `tf.data`. Here we will create a simple iterator for retrieving training batches."]},{"cell_type":"code","execution_count":85,"metadata":{"id":"m-3G9JI3b0is"},"outputs":[],"source":["class BatchGenerator:\n","\n","    def __init__(self, images, labels, batch_size=128):\n","        self.index = 0\n","        self.images = images\n","        self.labels = labels\n","        self.batch_size = batch_size\n","\n","    def next(self):\n","        images = self.images[self.index : self.index + self.batch_size]\n","        labels = self.labels[self.index : self.index + self.batch_size]\n","        self.index += self.batch_size\n","        return images, labels"]},{"cell_type":"markdown","metadata":{"id":"ZS9WrR5icG4G"},"source":["Let's try it on the MNIST data."]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1626925443725,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"pAKNUkujZwTG","outputId":"d31a9858-a5d2-4f2c-cd3a-a61c6e8a9089"},"outputs":[{"name":"stdout","output_type":"stream","text":["x: (128, 784)\n","y: (128,)\n"]}],"source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype('float32') / 255\n","\n","batch_generator = BatchGenerator(train_images, train_labels)\n","x, y = batch_generator.next()\n","print(f'x: {x.shape}')\n","print(f'y: {y.shape}')"]},{"cell_type":"markdown","metadata":{"id":"jJil0L1MyzIy"},"source":["## Task 3 Training the model\n","\n","As mentioned in the lecture. training a neural network involves a loop with the following steps:\n","\n","1. Compute the predictions of the examples in the batch\n","2. Compute the loss value for these predictions given the actual labels\n","3. Compute the gradient of the loss with regard to the model’s weights\n","4. Move the weights by a small amount in the direction opposite to the gradient\n","\n","These four steps comprise one **training step**."]},{"cell_type":"code","execution_count":87,"metadata":{"id":"5hVfO79afq98"},"outputs":[],"source":["learning_rate = 1e-3\n","\n","def update_weights(gradients, weights):\n","    for g, w in zip(gradients, model.weights):\n","        w.assign_sub(g * learning_rate)\n","\n","def one_training_step(model, images_batch, labels_batch):\n","    with tf.GradientTape() as tape:\n","      predictions = model(images_batch) ## 1. Compute the predictions of the examples in the batch \n","      per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n","          labels_batch, predictions) \n","      average_loss = tf.reduce_mean(per_sample_losses) ## 2. Compute the loss value for these predictions given the actual labels\n","    gradients = tape.gradient(average_loss, model.weights) ## 3. Compute the gradient of the loss with regard to the model’s weights\n","    update_weights(gradients, model.weights) ## 4. Move the weights by a small amount in the direction opposite to the gradient\n","    return average_loss"]},{"cell_type":"markdown","metadata":{"id":"98d3KS-5hS9B"},"source":["Let's test-run it with a training batch."]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1626925886924,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"jBSJibnBf6Cw","outputId":"5a121acb-4ed3-47da-ad88-c2fc3d5c5b61"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=2.3479156>"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["one_training_step(model, x, y)"]},{"cell_type":"markdown","metadata":{"id":"fkr_elRrhrbA"},"source":["Knowing that it is working, we can add a for-loop. Actually, we will use two nested for-loops: the outer for-loop to keep track of the number of epochs and the inner for-loop to iterate through the whole training data (multiple mini-batches). \n","\n"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"DFr4pexgh88Z"},"outputs":[],"source":["def fit(model, images, labels, epochs, batch_size=64):\n","    for epoch_counter in range(epochs):\n","      print('Epoch %d' % epoch_counter)\n","      batch_generator = BatchGenerator(images, labels)\n","      for batch_counter in range(len(images) // batch_size):\n","          images_batch, labels_batch = batch_generator.next()\n","          loss = one_training_step(model, images_batch, labels_batch)\n","          if batch_counter % 100 == 0:\n","              print('loss at batch %d: %.2f' % (batch_counter, loss))"]},{"cell_type":"markdown","metadata":{"id":"tWxT0QKVbOEs"},"source":["Now we are ready to train the model. Specify 5 epochs."]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112264,"status":"ok","timestamp":1626926138208,"user":{"displayName":"Antonio Robles-Kelly","photoUrl":"","userId":"12004615958940169307"},"user_tz":-600},"id":"KMZJ9kVMiBM5","outputId":"19f0ead3-8904-44a0-eeb6-491074f48abe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n","loss at batch 0: 2.35\n","loss at batch 100: 2.24\n","loss at batch 200: 2.15\n","loss at batch 300: 2.03\n","loss at batch 400: 1.96\n","Epoch 1\n","loss at batch 0: 1.86\n","loss at batch 100: 1.83\n","loss at batch 200: 1.71\n","loss at batch 300: 1.64\n","loss at batch 400: 1.61\n","Epoch 2\n","loss at batch 0: 1.50\n","loss at batch 100: 1.51\n","loss at batch 200: 1.38\n","loss at batch 300: 1.35\n","loss at batch 400: 1.35\n","Epoch 3\n","loss at batch 0: 1.23\n","loss at batch 100: 1.27\n","loss at batch 200: 1.13\n","loss at batch 300: 1.14\n","loss at batch 400: 1.16\n","Epoch 4\n","loss at batch 0: 1.04\n","loss at batch 100: 1.08\n","loss at batch 200: 0.95\n","loss at batch 300: 0.99\n","loss at batch 400: 1.02\n","Epoch 5\n","loss at batch 0: 0.90\n","loss at batch 100: 0.94\n","loss at batch 200: 0.82\n","loss at batch 300: 0.87\n","loss at batch 400: 0.92\n","Epoch 6\n","loss at batch 0: 0.80\n","loss at batch 100: 0.84\n","loss at batch 200: 0.72\n","loss at batch 300: 0.79\n","loss at batch 400: 0.85\n","Epoch 7\n","loss at batch 0: 0.73\n","loss at batch 100: 0.76\n","loss at batch 200: 0.65\n","loss at batch 300: 0.72\n","loss at batch 400: 0.79\n","Epoch 8\n","loss at batch 0: 0.67\n","loss at batch 100: 0.70\n","loss at batch 200: 0.59\n","loss at batch 300: 0.67\n","loss at batch 400: 0.74\n","Epoch 9\n","loss at batch 0: 0.62\n","loss at batch 100: 0.65\n","loss at batch 200: 0.55\n","loss at batch 300: 0.63\n","loss at batch 400: 0.71\n","Epoch 10\n","loss at batch 0: 0.59\n","loss at batch 100: 0.61\n","loss at batch 200: 0.51\n","loss at batch 300: 0.60\n","loss at batch 400: 0.68\n","Epoch 11\n","loss at batch 0: 0.56\n","loss at batch 100: 0.57\n","loss at batch 200: 0.48\n","loss at batch 300: 0.57\n","loss at batch 400: 0.65\n","Epoch 12\n","loss at batch 0: 0.53\n","loss at batch 100: 0.55\n","loss at batch 200: 0.46\n","loss at batch 300: 0.55\n","loss at batch 400: 0.63\n","Epoch 13\n","loss at batch 0: 0.51\n","loss at batch 100: 0.52\n","loss at batch 200: 0.44\n","loss at batch 300: 0.53\n","loss at batch 400: 0.61\n","Epoch 14\n","loss at batch 0: 0.49\n","loss at batch 100: 0.50\n","loss at batch 200: 0.42\n","loss at batch 300: 0.51\n","loss at batch 400: 0.59\n","Epoch 15\n","loss at batch 0: 0.48\n","loss at batch 100: 0.48\n","loss at batch 200: 0.40\n","loss at batch 300: 0.50\n","loss at batch 400: 0.58\n","Epoch 16\n","loss at batch 0: 0.46\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/var/folders/z_/xphnyhxs03sg7p8v5dgkr10w0000gn/T/ipykernel_1329/1107437596.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/var/folders/z_/xphnyhxs03sg7p8v5dgkr10w0000gn/T/ipykernel_1329/4246071118.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, images, labels, epochs, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mbatch_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mimages_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss at batch %d: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/var/folders/z_/xphnyhxs03sg7p8v5dgkr10w0000gn/T/ipykernel_1329/1852512830.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, images_batch, labels_batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 1. Compute the predictions of the examples in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n\u001b[1;32m     11\u001b[0m           labels_batch, predictions) \n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0maverage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_sample_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 2. Compute the loss value for these predictions given the actual labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 3. Compute the gradient of the loss with regard to the model’s weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## 4. Move the weights by a small amount in the direction opposite to the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maverage_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2541\u001b[0m   \"\"\"\n\u001b[1;32m   2542\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2543\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2544\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2545\u001b[0;31m       gen_math_ops.mean(\n\u001b[0m\u001b[1;32m   2546\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m           name=name))\n","\u001b[0;32m~/miniconda3/envs/learn_dl/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6512\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6513\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6514\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6515\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6517\u001b[0m       return mean_eager_fallback(\n\u001b[1;32m   6518\u001b[0m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fit(model, train_images, train_labels, epochs=50, batch_size=128)"]},{"cell_type":"markdown","metadata":{"id":"9ZH-m1ySjAAe"},"source":["**exercise** \n","\n","1. Write a program to evaluate the accuracy of the model and evaluate the accuracy on both training and test datasets.\n","\n","2. Modify the code above so that you collect the gradients at each layer and each epoch.\n"]},{"cell_type":"markdown","metadata":{"id":"cbd7zbd1NW42"},"source":["## Additional resources\n","\n","- [Tensorflow, The Confusing Parts (1)](https://jacobbuckman.com/2018-06-25-tensorflow-the-confusing-parts-1/). Don't worry if some parts are still \"confusing\" after reading this."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"SIT744_prac_4_colab.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
